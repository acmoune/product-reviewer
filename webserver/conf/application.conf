play.modules.enabled += "modules.AppModule"

pidfile.path = "/dev/null"

play.http.secret.key = "6cde343a8ddf144ad9afab30c0ee7060edc5a69b81b79d9b90246145bbd96842b69d64cf8c623c7c974077e0b1617151cb372ad1899ed0823ad5278d487a942712365489"


play.filters.enabled += "play.filters.cors.CORSFilter"

play.filters.cors {
  allowedOrigins = ["http://localhost:9000", "http://localhost:3000"]
  allowedHttpMethods = ["GET", "POST", "PATCH", "DELETE", "PUT"]
}

play.filters.hosts {
  allowed = ["localhost:9000", "localhost:3000"]
}

kafka {
  bootstrap.servers = "localhost:9092"
  bootstrap.servers = ${?KAFKA_BOOTSTRAP_SERVERS}

  schema.registry.url = "http://localhost:8081"
  schema.registry.url = ${?SCHEMA_REGISTRY_URL}

  security.eventsource.topic.name = "security-eventsource"
  security.eventsource.topic.name = ${?SECURITY_EVENTSOURCE_TOPIC_NAME}

  reviews.eventsource.topic.name = "reviews-eventsource"
  reviews.eventsource.topic.name = ${?REVIEWS_EVENTSOURCE_TOPIC_NAME}

  tasks.changelog.topic.name = "tasks-changelog"
  tasks.changelog.topic.name = ${?TASKS_CHANGELOG_TOPIC_NAME}

  stats.changelog.topic.name = "stats-changelog"
  stats.changelog.topic.name = ${?STATS_CHANGELOG_TOPIC_NAME}
}

datastax-java-driver {
  basic {
    contact-points = [ "localhost:9042" ]
    contact-points = [ ${?CONTACT_POINTS} ]

    load-balancing-policy.local-datacenter = datacenter1
    load-balancing-policy.local-datacenter = ${?LOAD_BALANCING_LOCAL_DATACENTER}

    session-keyspace = proreviewer
    session-keyspace = ${?SESSION_KEYSPACE}
  }
}

akka.kafka.consumer {
  # Tuning property of scheduled polls.
  # poll-interval = 50ms

  # Tuning property of the `KafkaConsumer.poll` parameter.
  # Note that non-zero value means that the thread that
  # is executing the stage will be blocked.
  # poll-timeout = 50ms

  # The stage will await outstanding offset commit requests before
  # shutting down, but if that takes longer than this timeout it will
  # stop forcefully.
  # stop-timeout = 30s

  # How long to wait for `KafkaConsumer.close`
  # close-timeout = 20s

  # If offset commit requests are not completed within this timeout
  # the returned Future is completed `CommitTimeoutException`.
  # commit-timeout = 15s

  # If commits take longer than this time a warning is logged
  # commit-time-warning = 1s

  # If for any reason `KafkaConsumer.poll` blocks for longer than the configured
  # poll-timeout then it is forcefully woken up with `KafkaConsumer.wakeup`.
  # The KafkaConsumerActor will throw
  # `org.apache.kafka.common.errors.WakeupException` which will be ignored
  # until `max-wakeups` limit gets exceeded.
  # wakeup-timeout = 60s

  # After exceeding maxinum wakeups the consumer will stop and the stage and fail.
  # Setting it to 0 will let it ignore the wakeups and try to get the polling done forever.
  # max-wakeups = 10

  # If set to a finite duration, the consumer will re-send the last committed offsets periodically
  # for all assigned partitions. See https://issues.apache.org/jira/browse/KAFKA-4682.
  # commit-refresh-interval = infinite

  # If enabled, log stack traces before waking up the KafkaConsumer to give
  # some indication why the KafkaConsumer is not honouring the `poll-timeout`
  #wakeup-debug = true

  # Fully qualified config path which holds the dispatcher configuration
  # to be used by the KafkaConsumerActor. Some blocking may occur.
  # use-dispatcher = "akka.kafka.default-dispatcher"

  # Properties defined by org.apache.kafka.clients.consumer.ConsumerConfig
  # can be defined in this configuration section.
  kafka-clients {
    # auto-commit disabled by default
    # Setting enable.auto.commit means that offsets are committed automatically
    #  with a frequency controlled by the config auto.commit.interval.ms.
    enable.auto.commit = true

    bootstrap.servers = "localhost:9092"
    bootstrap.servers = ${?KAFKA_BOOTSTRAP_SERVERS}
    group.id = "reviews-socket"

    auto.offset.reset = "earliest"
  }

  # Time to wait for pending requests when a partition is closed
  # wait-close-partition = 500ms
}

app {
  product.id = "63ad6a48-b989-4f1e-ae4e-d314e72d6dc3"
}